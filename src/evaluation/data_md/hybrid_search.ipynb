{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c4cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from qdrant_client.http import models\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForMaskedLM, BitsAndBytesConfig\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.models import PointStruct, SparseVector\n",
    "\n",
    "# ==========================================\n",
    "# 1. KONFIGURASI DAN UTILITAS\n",
    "# ==========================================\n",
    "# Model IDs\n",
    "DENSE_MODEL_ID = \"Qwen/Qwen3-Embedding-4B\"\n",
    "SPARSE_MODEL_ID = \"naver/splade-v3\"\n",
    "\n",
    "# Setup Device (GPU Prioritas)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üöÄ Running on: {device}\")\n",
    "\n",
    "# Konfigurasi Kuantisasi 4-bit (Hanya aktif jika di CUDA)\n",
    "bnb_config = None\n",
    "if device == \"cuda\":\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "class CustomEmbedder:\n",
    "    def __init__(self):\n",
    "        print(\"‚è≥ Loading Dense Model (Qwen 4-bit)...\")\n",
    "        self.dense_tokenizer = AutoTokenizer.from_pretrained(DENSE_MODEL_ID, trust_remote_code=True)\n",
    "        \n",
    "        # Load Model dengan Kuantisasi\n",
    "        self.dense_model = AutoModel.from_pretrained(\n",
    "            DENSE_MODEL_ID,\n",
    "            trust_remote_code=True,\n",
    "            quantization_config=bnb_config, # Aktifkan 4-bit\n",
    "            device_map=\"auto\" if device == \"cuda\" else None,\n",
    "            torch_dtype=torch.float16 if device == \"cuda\"\n",
    "        )\n",
    "        # Jika CPU, manual pindah (karena quantization_config hanya support GPU biasanya)\n",
    "        if device == \"cpu\":\n",
    "            self.dense_model.to(\"cpu\")\n",
    "\n",
    "        print(\"‚è≥ Loading Sparse Model (Splade v3)...\")\n",
    "        self.sparse_tokenizer = AutoTokenizer.from_pretrained(SPARSE_MODEL_ID)\n",
    "        self.sparse_model = AutoModelForMaskedLM.from_pretrained(SPARSE_MODEL_ID)\n",
    "        self.sparse_model.to(device) # Pindah model ke GPU\n",
    "\n",
    "    def get_dense_vector(self, text):\n",
    "        \"\"\"Mengubah teks menjadi vektor dense 1536 dimensi (Qwen)\"\"\"\n",
    "        # 1. Tokenize\n",
    "        inputs = self.dense_tokenizer(\n",
    "            text, \n",
    "            max_length=8192, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # 2. PINDAHKAN INPUT KE GPU (FIX ERROR DEVICE)\n",
    "        inputs = {k: v.to(self.dense_model.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.dense_model(**inputs)\n",
    "            # Untuk GTE-Qwen, embedding diambil dari last_hidden_state pada token terakhir (EOS)\n",
    "            # Sesuai dokumentasi resmi Alibaba-NLP\n",
    "            embeddings = last_token_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "            \n",
    "            # Normalisasi\n",
    "            embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "            \n",
    "        return embeddings[0].cpu().tolist()\n",
    "\n",
    "    def get_sparse_vector(self, text):\n",
    "        \"\"\"Mengubah teks menjadi sparse vector (Splade v3)\"\"\"\n",
    "        # 1. Tokenize\n",
    "        inputs = self.sparse_tokenizer(\n",
    "            text, \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True, \n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        # 2. PINDAHKAN INPUT KE GPU (FIX ERROR DEVICE)\n",
    "        inputs = {k: v.to(self.sparse_model.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.sparse_model(**inputs)\n",
    "        \n",
    "        # 3. Logika SPLADE (ReLU -> Log -> Max)\n",
    "        logits = outputs.logits[0] # (seq_len, vocab_size)\n",
    "        attention_mask = inputs[\"attention_mask\"][0].unsqueeze(-1)\n",
    "        \n",
    "        # SPLADE formula\n",
    "        relu_log = torch.log(1 + torch.relu(logits))\n",
    "        weighted_log = relu_log * attention_mask\n",
    "        \n",
    "        # Max Pooling (ambil nilai maksimum tiap token di seluruh sequence)\n",
    "        max_val, _ = torch.max(weighted_log, dim=0)\n",
    "        \n",
    "        # Filter nilai 0 (Sparse)\n",
    "        indices = torch.nonzero(max_val).squeeze().cpu().tolist()\n",
    "        values = max_val[indices].cpu().tolist()\n",
    "        \n",
    "        # Handle jika indices cuma 1 angka (bukan list)\n",
    "        if isinstance(indices, int):\n",
    "            indices = [indices]\n",
    "            values = [values]\n",
    "            \n",
    "        return SparseVector(indices=indices, values=values)\n",
    "\n",
    "def last_token_pool(last_hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Helper function khusus untuk Qwen/GTE embedding\"\"\"\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. MAIN LOGIC\n",
    "# ==========================================\n",
    "\n",
    "# Inisialisasi Embedder\n",
    "embedder = CustomEmbedder()\n",
    "\n",
    "# Inisialisasi Qdrant (Local Mode)\n",
    "print(\"\\nüíΩ Membuka database Qdrant lokal...\")\n",
    "client = QdrantClient(path=\"./qdrant_custom_db\") \n",
    "COLLECTION_NAME = \"hybrid_qwen_splade\"\n",
    "\n",
    "# Setup Collection (Hapus dulu kalau sudah ada biar bersih)\n",
    "if client.collection_exists(COLLECTION_NAME):\n",
    "    client.delete_collection(COLLECTION_NAME)\n",
    "\n",
    "print(\"‚öôÔ∏è Membuat Collection baru...\")\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config={\n",
    "        \"dense_vector\": models.VectorParams(\n",
    "            size=2560,\n",
    "            distance=models.Distance.COSINE\n",
    "        )\n",
    "    },\n",
    "    sparse_vectors_config={\n",
    "        \"sparse_vector\": models.SparseVectorParams()\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "headers_to_split_on = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\")]\n",
    "md_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "md_path = \"C:\\\\Users\\\\Ilmu Komputer\\\\OneDrive\\\\Desktop\\\\portofolio\\\\RAG\\\\defi-rag-agent\\\\src\\\\evaluation\\\\data_md\\\\parsed_document.md\"\n",
    "\n",
    "with open(md_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    file_content = f.read()\n",
    "    # docs ini adalah list dari objek Document, BUKAN list string\n",
    "    docs = md_splitter.split_text(file_content) \n",
    "\n",
    "print(\"üöÄ Mulai proses embedding dan upload...\")\n",
    "points = []\n",
    "\n",
    "# Ubah nama variabel loop dari 'text' ke 'doc' agar tidak bingung\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"   Processing doc {i+1}/{len(docs)}...\")\n",
    "    \n",
    "    # AMBIL CONTENT TEKS NYA SAJA\n",
    "    real_text = doc.page_content  \n",
    "    \n",
    "    # (Opsional) Gabungkan metadata header ke dalam teks untuk konteks embedding yang lebih baik\n",
    "    # context_text = f\"{doc.metadata} \\n {real_text}\" \n",
    "    # Tapi untuk sekarang kita pakai real_text saja agar sesuai ekspektasi Anda:\n",
    "    \n",
    "    # Generate vectors (sekarang inputnya sudah pasti string)\n",
    "    d_vec = embedder.get_dense_vector(real_text)\n",
    "    s_vec = embedder.get_sparse_vector(real_text)\n",
    "    \n",
    "    # Siapkan payload\n",
    "    # Kita masukkan juga metadata (header) agar nanti bisa difilter di Qdrant\n",
    "    payload_data = {\n",
    "        \"text\": real_text,\n",
    "        \"metadata\": doc.metadata \n",
    "    }\n",
    "\n",
    "    # Buat PointStruct\n",
    "    points.append(PointStruct(\n",
    "        id=i,\n",
    "        vector={\n",
    "            \"dense_vector\": d_vec,\n",
    "            \"sparse_vector\": s_vec\n",
    "        },\n",
    "        payload=payload_data\n",
    "    ))\n",
    "\n",
    "# Upload ke Qdrant\n",
    "client.upsert(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    points=points\n",
    ")\n",
    "print(\"‚úÖ Data berhasil diupload!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. FUNGSI PENCARIAN\n",
    "# ==========================================\n",
    "def search_hybrid(query_text):\n",
    "    print(f\"\\nüîç Query: '{query_text}'\")\n",
    "    \n",
    "    # Embed Query\n",
    "    q_dense = embedder.get_dense_vector(query_text)\n",
    "    q_sparse = embedder.get_sparse_vector(query_text)\n",
    "    \n",
    "    # Search dengan RRF (Reciprocal Rank Fusion)\n",
    "    results = client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=q_dense,\n",
    "                using=\"dense_vector\",\n",
    "                limit=10\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=q_sparse,\n",
    "                using=\"sparse_vector\",\n",
    "                limit=10\n",
    "            ),\n",
    "        ],\n",
    "        query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        limit=3\n",
    "    )\n",
    "    \n",
    "    for hit in results.points:\n",
    "        print(f\"   Score: {hit.score:.4f} | Text: {hit.payload['text']}\")\n",
    "\n",
    "# Test Case\n",
    "search_hybrid(\"Bagaimana membuat nasi goreng dengan aroma smoky?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ab945",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_hybrid(\"apa matakuliah yang harus diambil prodi Bimbingan konseling semester 1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc907405",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_hybrid(\"Apa tugas dosen PA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. FUNGSI PENCARIAN\n",
    "# ==========================================\n",
    "def search_hybrid(query_text):\n",
    "    print(f\"\\nüîç Query: '{query_text}'\")\n",
    "    \n",
    "    # Embed Query\n",
    "    q_dense = embedder.get_dense_vector(query_text)\n",
    "    q_sparse = embedder.get_sparse_vector(query_text)\n",
    "    \n",
    "    # Search dengan RRF (Reciprocal Rank Fusion)\n",
    "    results = client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=q_dense,\n",
    "                using=\"dense_vector\",\n",
    "                limit=10\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=q_sparse,\n",
    "                using=\"sparse_vector\",\n",
    "                limit=10\n",
    "            ),\n",
    "        ],\n",
    "        query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        limit=3\n",
    "    )\n",
    "    \n",
    "    for i, hit in enumerate(results.points, start=1):\n",
    "        print(f\"--- RESULT {i} ---\")                 # Pemisah antar looping\n",
    "        print(f\"Score: {hit.score:.4f}\")            # Tampilkan skor\n",
    "        print(f\"Text:\\n{hit.payload['text']}\")      # Teks di bawah skor\n",
    "        print(\"-\" * 40)                             # Garis pemisah tambahan\n",
    "\n",
    "\n",
    "# Test Case\n",
    "search_hybrid(\"Apa makna Duduk bersila dewa ganesha di logo undiksha?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_hybrid(\"Apa warna bendera FMIPA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a82ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_hybrid(\"Bagaimana Prosedur Permohonan Aktif Kembali Setelah Cuti Akademik \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d981ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_hybrid(\"Apa visi universitas pendidikan ganesha?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e96164",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_hybrid(\"Apa visi misi universitas pendidikan ganesha?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_hybrid(\"Berapa jumlah sks yang dapat diambil jika IP diatas 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2068b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_hybrid(\"Berapa min kehadiran untuk mengikuti UAS?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c2df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_hybrid(\"Butuh berapa SKS agar mahasiswa dapat mengajukan Skripsi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dacc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_hybrid(\"Pakaian apa yang tidak diperkenankan untuk mengikuti perkuliahan?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c542df",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_hybrid(\"saya adalah mahasiswa ilkom semester 7, bisa ga pindah ke prodi pendidikan bahasa inggris?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfc14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_hybrid(\"siapa aja dosen di prodi biologi?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085f754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running on: cuda\n",
      "‚è≥ Loading Dense Model (Qwen 4-bit)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c34b28a8e74be8a09ab30ce61be74e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Loading Sparse Model (Splade v3)...\n",
      "\n",
      "üíΩ Membuka database Qdrant lokal...\n",
      "\n",
      "üîç Query: 'Berapa sks agar bisa ambil skripsi?'\n",
      "--- RESULT 1 ---\n",
      "Score: 0.8333\n",
      "Judul:\n",
      "{'Header 1': 'Skripsi'}\n",
      "Text:\n",
      "| No  | Nama MK | Kode MK | Bobot SKS/JS | Semester | MK Prasyarat |\n",
      "| --- | ------- | ------- | ------------ | -------- | ------------ |\n",
      "| 72. | Skripsi | MNJ1877 | 6/6          | 8        |              |  \n",
      "Jumlah SKS: 6/6  \n",
      "TOTAL SKS: 152/152  \n",
      "Keterangan: Untuk mata kuliah bersyarat dapat ditempuh jika mata kuliah yang diprasyaratkan telah memperoleh nilai minimal C.\n",
      "----------------------------------------\n",
      "--- RESULT 2 ---\n",
      "Score: 0.5000\n",
      "Judul:\n",
      "{'Header 1': '7.1.1 Penjelasan Umum'}\n",
      "Text:\n",
      "1. Dalam keadaan terpaksa, seorang mahasiswa dapat mengambil cuti akademik, yaitu menghentikan studinya untuk sementara waktu atas ijin Dekan.\n",
      "2. Cuti Akademik hanya dapat dilaksanakan sekali selama masa studi, dengan batas waktu maksimal 1 semester.\n",
      "3. Pada akhir semester berjalan mahasiswa harus melapor untuk aktif kembali, jika tidak melapor untuk aktif kembali mahasiswa bersangkutan dianggap drop out (DO).\n",
      "4. Waktu yang dihabiskan selama cuti akademik tidak dihitung dalam total masa studi.\n",
      "5. Selama cuti akademik mahasiswa tersebut dibebaskan dari kewajiban membayar UKT.\n",
      "6. Mahasiswa yang mengambil cuti akademik dapat diterima kembali sebagai mahasiswa aktif dalam kedudukan semula setelah memenuhi persyaratan administrasi dan mendapatkan surat ijin untuk aktif kuliah kembali dari Dekan.\n",
      "7. Pada saat aktif kuliah setelah mengambil cuti kuliah mahasiswa hanya bisa memprogramkan mata kuliah sebanyak 14 sks karena selama cuti IP mahasiswa bersangkutan dianggap nol.\n",
      "8. Batas waktu pengajuan cuti akademik dan aktif kembali diatur dalam kalender akademik.\n",
      "----------------------------------------\n",
      "--- RESULT 3 ---\n",
      "Score: 0.3333\n",
      "Judul:\n",
      "{'Header 1': '8.1.3 Prosedur Pengajuan Rancangan Penelitian'}\n",
      "Text:\n",
      "1. Mahasiswa yang telah mencapai 120 sks boleh mengajukan usulan penelitian kepada Ketua Program Studi dengan mengikuti ketentuan yang diatur pada Pedoman Penulisan Skripsi.\n",
      "2. Format dan cakupan usulan penelitian diatur dalam Pedoman Penulisan Karya Ilmiah yang ditetapkan oleh Undiksha.\n",
      "3. Penilaian usulan penelitian dapat dilakukan oleh Ketua Program Studi, atau forum seminar, sesuai dengan kondisi dan kesepakatan di Program Studi yang bersangkutan.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from qdrant_client.http import models\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForMaskedLM, BitsAndBytesConfig\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.models import PointStruct, SparseVector\n",
    "\n",
    "# ==========================================\n",
    "# 1. KONFIGURASI DAN UTILITAS\n",
    "# ==========================================\n",
    "# Model IDs\n",
    "DENSE_MODEL_ID = \"Qwen/Qwen3-Embedding-4B\"\n",
    "SPARSE_MODEL_ID = \"naver/splade-v3\"\n",
    "\n",
    "# Setup Device (GPU Prioritas)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üöÄ Running on: {device}\")\n",
    "\n",
    "# Konfigurasi Kuantisasi 4-bit (Hanya aktif jika di CUDA)\n",
    "bnb_config = None\n",
    "if device == \"cuda\":\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "class CustomEmbedder:\n",
    "    def __init__(self):\n",
    "        print(\"‚è≥ Loading Dense Model (Qwen 4-bit)...\")\n",
    "        self.dense_tokenizer = AutoTokenizer.from_pretrained(DENSE_MODEL_ID, trust_remote_code=True)\n",
    "        \n",
    "        # Load Model dengan Kuantisasi\n",
    "        self.dense_model = AutoModel.from_pretrained(\n",
    "            DENSE_MODEL_ID,\n",
    "            trust_remote_code=True,\n",
    "            quantization_config=bnb_config, # Aktifkan 4-bit\n",
    "            device_map=\"auto\" if device == \"cuda\" else None,\n",
    "            torch_dtype=torch.float16 if device == \"cuda\" else \"cpu\"\n",
    "        )\n",
    "        # Jika CPU, manual pindah (karena quantization_config hanya support GPU biasanya)\n",
    "        if device == \"cpu\":\n",
    "            self.dense_model.to(\"cpu\")\n",
    "\n",
    "        print(\"‚è≥ Loading Sparse Model (Splade v3)...\")\n",
    "        self.sparse_tokenizer = AutoTokenizer.from_pretrained(SPARSE_MODEL_ID)\n",
    "        self.sparse_model = AutoModelForMaskedLM.from_pretrained(SPARSE_MODEL_ID)\n",
    "        self.sparse_model.to(device) # Pindah model ke GPU\n",
    "\n",
    "    def get_dense_vector(self, text):\n",
    "        \"\"\"Mengubah teks menjadi vektor dense 1536 dimensi (Qwen)\"\"\"\n",
    "        # 1. Tokenize\n",
    "        inputs = self.dense_tokenizer(\n",
    "            text, \n",
    "            max_length=8192, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # 2. PINDAHKAN INPUT KE GPU (FIX ERROR DEVICE)\n",
    "        inputs = {k: v.to(self.dense_model.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.dense_model(**inputs)\n",
    "            # Untuk GTE-Qwen, embedding diambil dari last_hidden_state pada token terakhir (EOS)\n",
    "            # Sesuai dokumentasi resmi Alibaba-NLP\n",
    "            embeddings = last_token_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "            \n",
    "            # Normalisasi\n",
    "            embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "            \n",
    "        return embeddings[0].cpu().tolist()\n",
    "\n",
    "    def get_sparse_vector(self, text):\n",
    "        \"\"\"Mengubah teks menjadi sparse vector (Splade v3)\"\"\"\n",
    "        # 1. Tokenize\n",
    "        inputs = self.sparse_tokenizer(\n",
    "            text, \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True, \n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        # 2. PINDAHKAN INPUT KE GPU (FIX ERROR DEVICE)\n",
    "        inputs = {k: v.to(self.sparse_model.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.sparse_model(**inputs)\n",
    "        \n",
    "        # 3. Logika SPLADE (ReLU -> Log -> Max)\n",
    "        logits = outputs.logits[0] # (seq_len, vocab_size)\n",
    "        attention_mask = inputs[\"attention_mask\"][0].unsqueeze(-1)\n",
    "        \n",
    "        # SPLADE formula\n",
    "        relu_log = torch.log(1 + torch.relu(logits))\n",
    "        weighted_log = relu_log * attention_mask\n",
    "        \n",
    "        # Max Pooling (ambil nilai maksimum tiap token di seluruh sequence)\n",
    "        max_val, _ = torch.max(weighted_log, dim=0)\n",
    "        \n",
    "        # Filter nilai 0 (Sparse)\n",
    "        indices = torch.nonzero(max_val).squeeze().cpu().tolist()\n",
    "        values = max_val[indices].cpu().tolist()\n",
    "        \n",
    "        # Handle jika indices cuma 1 angka (bukan list)\n",
    "        if isinstance(indices, int):\n",
    "            indices = [indices]\n",
    "            values = [values]\n",
    "            \n",
    "        return SparseVector(indices=indices, values=values)\n",
    "\n",
    "def last_token_pool(last_hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Helper function khusus untuk Qwen/GTE embedding\"\"\"\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. MAIN LOGIC\n",
    "# ==========================================\n",
    "\n",
    "# Inisialisasi Embedder\n",
    "embedder = CustomEmbedder()\n",
    "\n",
    "# Inisialisasi Qdrant (Local Mode)\n",
    "print(\"\\nüíΩ Membuka database Qdrant lokal...\")\n",
    "client = QdrantClient(path=\"./qdrant_custom_db\") \n",
    "COLLECTION_NAME = \"hybrid_qwen_splade\"\n",
    "\n",
    "\n",
    "\n",
    "# 3. FUNGSI PENCARIAN\n",
    "# ==========================================\n",
    "def search_hybrid(query_text):\n",
    "    print(f\"\\nüîç Query: '{query_text}'\")\n",
    "    \n",
    "    # Embed Query\n",
    "    q_dense = embedder.get_dense_vector(query_text)\n",
    "    q_sparse = embedder.get_sparse_vector(query_text)\n",
    "    \n",
    "    # Search dengan RRF (Reciprocal Rank Fusion)\n",
    "    results = client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=q_dense,\n",
    "                using=\"dense_vector\",\n",
    "                limit=10\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=q_sparse,\n",
    "                using=\"sparse_vector\",\n",
    "                limit=10\n",
    "            ),\n",
    "        ],\n",
    "        query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        limit=3\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    for i, hit in enumerate(results.points, start=1):\n",
    "        print(f\"--- RESULT {i} ---\")                 # Pemisah antar looping\n",
    "        print(f\"Score: {hit.score:.4f}\")            # Tampilkan skor\n",
    "        print(f\"Judul:\\n{hit.payload['metadata']}\")      # Teks di bawah skor\n",
    "        print(f\"Text:\\n{hit.payload['text']}\")      # Teks di bawah skor\n",
    "        print(\"-\" * 40) \n",
    "\n",
    "# Test Case\n",
    "search_hybrid(\"Berapa sks agar bisa ambil skripsi?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7553d7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Query: 'Berapa sks yang setidaknya perlu dicapai agar bisa ambil topik skripsi?'\n",
      "--- RESULT 1 ---\n",
      "Score: 0.7500\n",
      "Judul:\n",
      "{'Header 1': '8.1.3 Prosedur Pengajuan Rancangan Penelitian'}\n",
      "Text:\n",
      "1. Mahasiswa yang telah mencapai 120 sks boleh mengajukan usulan penelitian kepada Ketua Program Studi dengan mengikuti ketentuan yang diatur pada Pedoman Penulisan Skripsi.\n",
      "2. Format dan cakupan usulan penelitian diatur dalam Pedoman Penulisan Karya Ilmiah yang ditetapkan oleh Undiksha.\n",
      "3. Penilaian usulan penelitian dapat dilakukan oleh Ketua Program Studi, atau forum seminar, sesuai dengan kondisi dan kesepakatan di Program Studi yang bersangkutan.\n",
      "----------------------------------------\n",
      "--- RESULT 2 ---\n",
      "Score: 0.5000\n",
      "Judul:\n",
      "{'Header 1': '8.1.5.2 Mekanisme Bimbingan Skripsi'}\n",
      "Text:\n",
      "1. Setiap langkah yang akan dikerjakan oleh mahasiswa, baik dalam proses penelitian maupun dalam penyusunan skripsi, harus lebih dahulu dikonsultasikan dengan dosen pembimbing. Mahasiswa yang belum berkonsultasi lebih dari tiga bulan setelah rancangan disetujui akan diberi peringatan oleh pembimbing. Apabila mahasiswa tidak pernah berkonsultasi lebih dari enam bulan, maka rancangan penelitiannya dinyatakan gagal oleh Ketua Program Studi.\n",
      "2. Ketua Program Studi, Dekan dan Rektor melakukan pemantauan terhadap pelaksanaan bimbingan skripsi.\n",
      "3. Dosen pembimbing skripsi melaksanakan tugas bimbingan sampai batas waktu yang ditentukan, yaitu enam bulan.\n",
      "4. Mahasiswa yang belum dapat menyelesaikan skripsi sampai batas waktu yang ditentukan, Ketua Program Studi dapat mengambil keputusan yang diperlukan sesuai dengan masukan pembimbing dan mahasiswa.\n",
      "5. Kalau timbul masalah berkaitan dengan proses bimbingan, pemecahan masalah atau keputusan akhir terletak pada pembimbingan utama.\n",
      "6. Jika mahasiswa tidak mendapat bimbingan dalam satu bulan atau lebih karena satu hal, maka mahasiswa tersebut harus melaporkan diri ke Ketua Program Studi.\n",
      "----------------------------------------\n",
      "--- RESULT 3 ---\n",
      "Score: 0.4762\n",
      "Judul:\n",
      "{'Header 1': '8.1.6 Penyelesaian Skripsi'}\n",
      "Text:\n",
      "1. Ketentuan penulisan naskah skripsi disesuaikan dengan pedoman penulisan skripsi yang berlaku di Undiksha.\n",
      "2. Saat menempuh ujian skripsi, mahasiswa belum diperkenankan menjilid skripsinya karena mungkin masih ada bagian‚Äëbagian yang harus direvisi atau kemungkinan tidak lulus (gagal).\n",
      "3. Mahasiswa yang dinyatakan telah lulus ujian skripsi tanpa revisi harus meminta surat keterangan dari pembimbing bahwa skripsi sudah boleh dijilid. Setelah itu mahasiswa bersangkutan dapat menjilid skripsinya.\n",
      "4. Mahasiswa yang sudah dinyatakan lulus skripsi tetapi dengan beberapa revisi, mahasiswa tersebut harus melakukan revisi sampai dinyatakan tuntas oleh penguji dan pembimbing, dan selanjutnya diberikan surat keterangan oleh pembimbing bahwa skripsi sudah boleh dijilid. Setelah itu mahasiswa bersangkutan dapat menjilid skripsinya.\n",
      "5. Skripsi dijilid dengan menggunakan hard cover (sampul keras) dengan warna sebagai berikut.  \n",
      "- a. Fakultas Ilmu Pendidikan: putih\n",
      "- b. Fakultas MIPA: hijau\n",
      "- c. Fakultas Hukum dan Ilmu Sosial: biru langit\n",
      "- d. Fakultas Bahasa dan Seni: kuning\n",
      "- e. Fakultas Teknik dan Kejuruan: biru dongker\n",
      "- f. Fakultas Olahraga dan Kesehatan: merah hati\n",
      "- g. Fakultas Ekonomi: oranye terang  \n",
      "6. Persetujuan skripsi diberikan oleh pembimbing utama dan pembimbing Wakil.\n",
      "7. Pengesahan skripsi dilakukan oleh Panitia Ujian yang terdiri atas:\n",
      "8. Ketua: Wakil Dekan I\n",
      "9. Sekretaris: Ketua Program Studi\n",
      "10. Yang mengesahkan: Dekan\n",
      "11. Mahasiswa yang sudah dinyatakan lulus skripsi wajib membuat artikel. Panjang artikel 10 ‚Äì 15 halaman termasuk bagian abstraknya. Artikel diketik dengan jenis huruf Times New Roman ukuran 12 dengan spasi 1,5. Abstrak pada artikel diketik dengan spasi tunggal. Ketentuan format artikel dapat disesuaikan dengan e‚Äëjournal Undiksha.\n",
      "12. Mahasiswa menyerahkan 1 eksemplar skripsi yang sudah dijilid ke Program Studi.\n",
      "13. Mahasiswa menyerahkan 1 eksemplar skripsi yang sudah dijilid dan CD yang memuat soft copy skripsi dan artikel ke Perpustakaan.\n",
      "14. Mahasiswa yang belum menyerahkan skripsi sesuai dengan ketentuan di atas tidak diperkenankan mendaftar wisuda dan tidak diperkenankan mengambil tanda lulus.  \n",
      "Pedoman Studi Universitas Pendidikan Ganesha Tahun 2017\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "search_hybrid(\"Berapa sks yang setidaknya perlu dicapai agar bisa ambil topik skripsi?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dced342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
