{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef2da93c",
   "metadata": {},
   "source": [
    "akhir code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8f3f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koneksi ke Firebase Firestore berhasil.\n",
      "Inisialisasi LLM dengan model: meta-llama/llama-4-scout\n",
      "Inisialisasi Evaluator dengan model: openai/gpt-4o-mini\n",
      "üßπ VRAM Cleaned. Usage: 0.00 GB\n",
      "‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6b9931ca0248ae8311712ebedd8a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Membaca file dataset: dataset_ragas_lengkap.xlsx\n",
      "‚öôÔ∏è Melakukan konversi format data (String -> List)...\n",
      "‚úÖ Data berhasil dimuat dan diproses.\n",
      "\n",
      "üöÄ Memulai Evaluasi Ragas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd7c9c5868342fa8b7baf5114e3b2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "üìä HASIL AKHIR SKOR RAGAS\n",
      "==============================\n",
      "{'context_precision': 0.7333, 'faithfulness': 0.7667, 'answer_relevancy': 0.4396, 'context_recall': 0.8000}\n",
      "==============================\n",
      "\n",
      "üíæ File hasil evaluasi disimpan: hasil_evaluasi_final.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from ast import literal_eval  # PENTING: Untuk mengubah string \"['...']\" kembali jadi list\n",
    "\n",
    "# Library Ragas & Evaluasi\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Import module custom Anda (hanya untuk evaluator judge)\n",
    "from resources import evaluator\n",
    "\n",
    "# =====================================================\n",
    "# STEP 0: BERSIHKAN MEMORI (VRAM)\n",
    "# =====================================================\n",
    "try:\n",
    "    del evaluator_embeddings\n",
    "    del results\n",
    "    del rag_dataset\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"üßπ VRAM Cleaned. Usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 1: KONFIGURASI MODEL (JUDGE & EMBEDDING)\n",
    "# =====================================================\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# LLM Judge (GPT-4o / Model Lain)\n",
    "evaluator_llm = evaluator\n",
    "\n",
    "print(\"‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\")\n",
    "evaluator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"Qwen/Qwen3-Embedding-4B\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',\n",
    "        'trust_remote_code': True,\n",
    "        'model_kwargs': {'quantization_config': bnb_config, 'device_map': 'auto'}\n",
    "    },\n",
    "    encode_kwargs={'normalize_embeddings': True, 'batch_size': 1},\n",
    "    multi_process=False \n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 2: LOAD DATASET DARI EXCEL (LANGSUNG EVALUASI)\n",
    "# =====================================================\n",
    "# Ganti nama file sesuai file excel Anda yang sudah lengkap/rapi\n",
    "file_path = \"dataset_ragas_lengkap.xlsx\" \n",
    "print(f\"üìÇ Membaca file dataset: {file_path}\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# --- FUNGSI PREPROCESSING KRUSIAL ---\n",
    "# Excel menyimpan list sebagai string, contoh: \"['dokumen A', 'dokumen B']\"\n",
    "# Kita harus mengubahnya kembali menjadi list Python sungguhan: ['dokumen A', 'dokumen B']\n",
    "def parse_contexts(x):\n",
    "    if isinstance(x, list):\n",
    "        return x  # Jika sudah list, biarkan\n",
    "    try:\n",
    "        # Mencoba mengubah string representasi list menjadi list asli\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        # Jika gagal (misal sel kosong atau format rusak), kembalikan list kosong\n",
    "        return []\n",
    "\n",
    "print(\"‚öôÔ∏è Melakukan konversi format data (String -> List)...\")\n",
    "# Terapkan fungsi ke kolom contexts\n",
    "if 'contexts' in df.columns:\n",
    "    df['contexts'] = df['contexts'].apply(parse_contexts)\n",
    "else:\n",
    "    raise ValueError(\"‚ùå Kolom 'contexts' tidak ditemukan di Excel!\")\n",
    "\n",
    "# Pastikan kolom ground_truth diperlakukan sebagai string (jika ada)\n",
    "if 'ground_truth' in df.columns:\n",
    "    df['ground_truth'] = df['ground_truth'].astype(str)\n",
    "\n",
    "# Pastikan kolom answer diperlakukan sebagai string\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "\n",
    "print(\"‚úÖ Data berhasil dimuat dan diproses.\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 3: JALANKAN EVALUASI RAGAS\n",
    "# =====================================================\n",
    "# Konversi DataFrame Pandas ke Dataset RAGAs\n",
    "rag_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "metrics = [context_precision, faithfulness, answer_relevancy, context_recall]\n",
    "\n",
    "print(\"\\nüöÄ Memulai Evaluasi Ragas...\")\n",
    "# Jalankan Evaluasi\n",
    "results = evaluate(\n",
    "    dataset=rag_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "# --- PRINT HASIL AKHIR ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"üìä HASIL AKHIR SKOR RAGAS\")\n",
    "print(\"=\"*30)\n",
    "print(results)\n",
    "print(\"=\"*30)\n",
    "\n",
    "# =====================================================\n",
    "# STEP 4: SAVE HASIL KE EXCEL BARU\n",
    "# =====================================================\n",
    "metrics_df = results.to_pandas()\n",
    "\n",
    "# Reset index untuk penggabungan yang aman\n",
    "df_reset = df.reset_index(drop=True)\n",
    "metrics_reset = metrics_df.reset_index(drop=True)\n",
    "\n",
    "# Gabungkan data asli dengan skor hasil evaluasi\n",
    "final_df = pd.concat([df_reset, metrics_reset], axis=1)\n",
    "\n",
    "# Hapus kolom duplikat jika ada\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "\n",
    "# Tentukan urutan kolom yang rapi untuk output\n",
    "cols_target = ['question', 'answer', 'contexts', 'ground_truth', \n",
    "               'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "final_cols = [c for c in cols_target if c in final_df.columns]\n",
    "final_df = final_df[final_cols]\n",
    "\n",
    "output_filename = \"hasil_evaluasi_final.xlsx\"\n",
    "final_df.to_excel(output_filename, index=False)\n",
    "print(f\"\\nüíæ File hasil evaluasi disimpan: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "276210bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koneksi ke Firebase Firestore berhasil.\n",
      "Inisialisasi LLM dengan model: meta-llama/llama-4-scout\n",
      "Inisialisasi Evaluator dengan model: openai/gpt-4o-mini\n",
      "üßπ VRAM Cleaned. Usage: 0.00 GB\n",
      "‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce2f6cfb753456a960a209fba14121e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Membaca file dataset: dataset_ragas_lengkap.xlsx\n",
      "‚öôÔ∏è Melakukan konversi format data (String -> List)...\n",
      "‚úÖ Data berhasil dimuat dan diproses.\n",
      "\n",
      "üöÄ Memulai Evaluasi Ragas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439dd04b46d84cae8ca13ae95de2b803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Exception raised in Job[25]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "üìä HASIL AKHIR SKOR RAGAS\n",
      "==============================\n",
      "{'context_precision': 0.7333, 'faithfulness': 0.8519, 'answer_relevancy': 0.4668, 'context_recall': 0.8000}\n",
      "==============================\n",
      "\n",
      "üíæ File hasil evaluasi disimpan: hasil_evaluasi_final.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from ast import literal_eval  # PENTING: Untuk mengubah string \"['...']\" kembali jadi list\n",
    "\n",
    "# Library Ragas & Evaluasi\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Import module custom Anda (hanya untuk evaluator judge)\n",
    "from resources import evaluator\n",
    "\n",
    "# =====================================================\n",
    "# STEP 0: BERSIHKAN MEMORI (VRAM)\n",
    "# =====================================================\n",
    "try:\n",
    "    del evaluator_embeddings\n",
    "    del results\n",
    "    del rag_dataset\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"üßπ VRAM Cleaned. Usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 1: KONFIGURASI MODEL (JUDGE & EMBEDDING)\n",
    "# =====================================================\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# LLM Judge (GPT-4o / Model Lain)\n",
    "evaluator_llm = evaluator\n",
    "\n",
    "print(\"‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\")\n",
    "evaluator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"Qwen/Qwen3-Embedding-4B\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',\n",
    "        'trust_remote_code': True,\n",
    "        'model_kwargs': {'quantization_config': bnb_config, 'device_map': 'auto'}\n",
    "    },\n",
    "    encode_kwargs={'normalize_embeddings': True, 'batch_size': 1},\n",
    "    multi_process=False \n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 2: LOAD DATASET DARI EXCEL (LANGSUNG EVALUASI)\n",
    "# =====================================================\n",
    "# Ganti nama file sesuai file excel Anda yang sudah lengkap/rapi\n",
    "file_path = \"dataset_ragas_lengkap.xlsx\" \n",
    "print(f\"üìÇ Membaca file dataset: {file_path}\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# --- FUNGSI PREPROCESSING KRUSIAL ---\n",
    "# Excel menyimpan list sebagai string, contoh: \"['dokumen A', 'dokumen B']\"\n",
    "# Kita harus mengubahnya kembali menjadi list Python sungguhan: ['dokumen A', 'dokumen B']\n",
    "def parse_contexts(x):\n",
    "    if isinstance(x, list):\n",
    "        return x  # Jika sudah list, biarkan\n",
    "    try:\n",
    "        # Mencoba mengubah string representasi list menjadi list asli\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        # Jika gagal (misal sel kosong atau format rusak), kembalikan list kosong\n",
    "        return []\n",
    "\n",
    "print(\"‚öôÔ∏è Melakukan konversi format data (String -> List)...\")\n",
    "# Terapkan fungsi ke kolom contexts\n",
    "if 'contexts' in df.columns:\n",
    "    df['contexts'] = df['contexts'].apply(parse_contexts)\n",
    "else:\n",
    "    raise ValueError(\"‚ùå Kolom 'contexts' tidak ditemukan di Excel!\")\n",
    "\n",
    "# Pastikan kolom ground_truth diperlakukan sebagai string (jika ada)\n",
    "if 'ground_truth' in df.columns:\n",
    "    df['ground_truth'] = df['ground_truth'].astype(str)\n",
    "\n",
    "# Pastikan kolom answer diperlakukan sebagai string\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "\n",
    "print(\"‚úÖ Data berhasil dimuat dan diproses.\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 3: JALANKAN EVALUASI RAGAS\n",
    "# =====================================================\n",
    "# Konversi DataFrame Pandas ke Dataset RAGAs\n",
    "rag_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "metrics = [context_precision, faithfulness, answer_relevancy, context_recall]\n",
    "\n",
    "print(\"\\nüöÄ Memulai Evaluasi Ragas...\")\n",
    "# Jalankan Evaluasi\n",
    "results = evaluate(\n",
    "    dataset=rag_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "# --- PRINT HASIL AKHIR ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"üìä HASIL AKHIR SKOR RAGAS\")\n",
    "print(\"=\"*30)\n",
    "print(results)\n",
    "print(\"=\"*30)\n",
    "\n",
    "# =====================================================\n",
    "# STEP 4: SAVE HASIL KE EXCEL BARU\n",
    "# =====================================================\n",
    "metrics_df = results.to_pandas()\n",
    "\n",
    "# Reset index untuk penggabungan yang aman\n",
    "df_reset = df.reset_index(drop=True)\n",
    "metrics_reset = metrics_df.reset_index(drop=True)\n",
    "\n",
    "# Gabungkan data asli dengan skor hasil evaluasi\n",
    "final_df = pd.concat([df_reset, metrics_reset], axis=1)\n",
    "\n",
    "# Hapus kolom duplikat jika ada\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "\n",
    "# Tentukan urutan kolom yang rapi untuk output\n",
    "cols_target = ['question', 'answer', 'contexts', 'ground_truth', \n",
    "               'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "final_cols = [c for c in cols_target if c in final_df.columns]\n",
    "final_df = final_df[final_cols]\n",
    "\n",
    "output_filename = \"hasil_evaluasi_final.xlsx\"\n",
    "final_df.to_excel(output_filename, index=False)\n",
    "print(f\"\\nüíæ File hasil evaluasi disimpan: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29bbbab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ VRAM Cleaned. Usage: 0.00 GB\n",
      "‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\n",
      "üìÇ Membaca file dataset: dataset_ragas_lengkap.xlsx\n",
      "‚öôÔ∏è Melakukan konversi format data (String -> List)...\n",
      "‚úÖ Data berhasil dimuat dan diproses.\n",
      "\n",
      "üöÄ Memulai Evaluasi Ragas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc247570677f4e8ba9eb09e8bf9cbdc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Exception raised in Job[33]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "üìä HASIL AKHIR SKOR RAGAS\n",
      "==============================\n",
      "{'context_precision': 0.6833, 'faithfulness': 0.7407, 'answer_relevancy': 0.6886, 'context_recall': 0.8000}\n",
      "==============================\n",
      "\n",
      "üíæ File hasil evaluasi disimpan: hasil_evaluasi_final_e5_base.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from ast import literal_eval  # PENTING: Untuk mengubah string \"['...']\" kembali jadi list\n",
    "from resources import evaluator\n",
    "evaluator_llm = evaluator\n",
    "\n",
    "# Library Ragas & Evaluasi\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Import module custom Anda (hanya untuk evaluator judge)\n",
    "from resources import evaluator\n",
    "\n",
    "# =====================================================\n",
    "# STEP 0: BERSIHKAN MEMORI (VRAM)\n",
    "# =====================================================\n",
    "try:\n",
    "    del evaluator_embeddings\n",
    "    del results\n",
    "    del rag_dataset\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"üßπ VRAM Cleaned. Usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 1: KONFIGURASI MODEL (JUDGE & EMBEDDING)\n",
    "# =====================================================\n",
    "print(\"‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\")\n",
    "\n",
    "evaluator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',   # Memaksa model berjalan di GPU\n",
    "        # 'trust_remote_code': True # Biasanya tidak wajib untuk e5-base, tapi boleh dibiarkan jika error\n",
    "    },\n",
    "    encode_kwargs={\n",
    "        'normalize_embeddings': True, # Wajib True untuk model E5 agar cosine similarity akurat\n",
    "        'batch_size': 32 # Saya naikkan dari 1. Karena tanpa kuantisasi, model ini ringan & cepat.\n",
    "    },\n",
    "    multi_process=False \n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 2: LOAD DATASET DARI EXCEL (LANGSUNG EVALUASI)\n",
    "# =====================================================\n",
    "# Ganti nama file sesuai file excel Anda yang sudah lengkap/rapi\n",
    "file_path = \"dataset_ragas_lengkap.xlsx\" \n",
    "print(f\"üìÇ Membaca file dataset: {file_path}\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# --- FUNGSI PREPROCESSING KRUSIAL ---\n",
    "# Excel menyimpan list sebagai string, contoh: \"['dokumen A', 'dokumen B']\"\n",
    "# Kita harus mengubahnya kembali menjadi list Python sungguhan: ['dokumen A', 'dokumen B']\n",
    "def parse_contexts(x):\n",
    "    if isinstance(x, list):\n",
    "        return x  # Jika sudah list, biarkan\n",
    "    try:\n",
    "        # Mencoba mengubah string representasi list menjadi list asli\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        # Jika gagal (misal sel kosong atau format rusak), kembalikan list kosong\n",
    "        return []\n",
    "\n",
    "print(\"‚öôÔ∏è Melakukan konversi format data (String -> List)...\")\n",
    "# Terapkan fungsi ke kolom contexts\n",
    "if 'contexts' in df.columns:\n",
    "    df['contexts'] = df['contexts'].apply(parse_contexts)\n",
    "else:\n",
    "    raise ValueError(\"‚ùå Kolom 'contexts' tidak ditemukan di Excel!\")\n",
    "\n",
    "# Pastikan kolom ground_truth diperlakukan sebagai string (jika ada)\n",
    "if 'ground_truth' in df.columns:\n",
    "    df['ground_truth'] = df['ground_truth'].astype(str)\n",
    "\n",
    "# Pastikan kolom answer diperlakukan sebagai string\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "\n",
    "print(\"‚úÖ Data berhasil dimuat dan diproses.\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 3: JALANKAN EVALUASI RAGAS\n",
    "# =====================================================\n",
    "# Konversi DataFrame Pandas ke Dataset RAGAs\n",
    "rag_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "metrics = [context_precision, faithfulness, answer_relevancy, context_recall]\n",
    "\n",
    "print(\"\\nüöÄ Memulai Evaluasi Ragas...\")\n",
    "# Jalankan Evaluasi\n",
    "results = evaluate(\n",
    "    dataset=rag_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "# --- PRINT HASIL AKHIR ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"üìä HASIL AKHIR SKOR RAGAS\")\n",
    "print(\"=\"*30)\n",
    "print(results)\n",
    "print(\"=\"*30)\n",
    "\n",
    "# =====================================================\n",
    "# STEP 4: SAVE HASIL KE EXCEL BARU\n",
    "# =====================================================\n",
    "metrics_df = results.to_pandas()\n",
    "\n",
    "# Reset index untuk penggabungan yang aman\n",
    "df_reset = df.reset_index(drop=True)\n",
    "metrics_reset = metrics_df.reset_index(drop=True)\n",
    "\n",
    "# Gabungkan data asli dengan skor hasil evaluasi\n",
    "final_df = pd.concat([df_reset, metrics_reset], axis=1)\n",
    "\n",
    "# Hapus kolom duplikat jika ada\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "\n",
    "# Tentukan urutan kolom yang rapi untuk output\n",
    "cols_target = ['question', 'answer', 'contexts', 'ground_truth', \n",
    "               'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "final_cols = [c for c in cols_target if c in final_df.columns]\n",
    "final_df = final_df[final_cols]\n",
    "\n",
    "output_filename = \"hasil_evaluasi_final_e5_base.xlsx\"\n",
    "final_df.to_excel(output_filename, index=False)\n",
    "print(f\"\\nüíæ File hasil evaluasi disimpan: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74552e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koneksi ke Firebase Firestore berhasil.\n",
      "Inisialisasi LLM dengan model: meta-llama/llama-4-scout\n",
      "Inisialisasi Evaluator dengan model: openai/gpt-4o-mini\n",
      "üßπ VRAM Cleaned. Usage: 0.00 GB\n",
      "‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803a3b02727d4566b8fb454d56c830ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf3d584a595468c9394faaf1e7927f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53c073c493a46a3b5a59f3bf57510d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de1ea33371247288de550792da5e68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f206dfa3e14b07b2cc275d2c710d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.19G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6057fff27d114201bcdc985c5a31b3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c6828140a344f9b3a7f248c1c061bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425f30e57dc34a53b212a2f8d6788aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b742c8aa9474d658bcc4596bc7a4b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62c934c4c4849c48e575f1b6162d875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Membaca file dataset: dataset_ragas_lengkap.xlsx\n",
      "‚öôÔ∏è Melakukan konversi format data (String -> List)...\n",
      "‚úÖ Data berhasil dimuat dan diproses.\n",
      "\n",
      "üöÄ Memulai Evaluasi Ragas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c867957d55448295502ffb38d1dd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n",
      "Requested n=3 with low temperature (None). Overriding temperature to 0.5 to ensure diversity.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "üìä HASIL AKHIR SKOR RAGAS\n",
      "==============================\n",
      "{'context_precision': 0.7333, 'faithfulness': 0.7667, 'answer_relevancy': 0.4692, 'context_recall': 0.8000}\n",
      "==============================\n",
      "\n",
      "üíæ File hasil evaluasi disimpan: hasil_evaluasi_final_e5_base.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from ast import literal_eval  # PENTING: Untuk mengubah string \"['...']\" kembali jadi list\n",
    "from resources import evaluator\n",
    "evaluator_llm = evaluator\n",
    "\n",
    "# Library Ragas & Evaluasi\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Import module custom Anda (hanya untuk evaluator judge)\n",
    "from resources import evaluator\n",
    "\n",
    "# =====================================================\n",
    "# STEP 0: BERSIHKAN MEMORI (VRAM)\n",
    "# =====================================================\n",
    "try:\n",
    "    del evaluator_embeddings\n",
    "    del results\n",
    "    del rag_dataset\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"üßπ VRAM Cleaned. Usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 1: KONFIGURASI MODEL (JUDGE & EMBEDDING)\n",
    "# =====================================================\n",
    "print(\"‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\")\n",
    "\n",
    "evaluator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"Qwen/Qwen3-Embedding-0.6B\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',   # Memaksa model berjalan di GPU\n",
    "        # 'trust_remote_code': True # Biasanya tidak wajib untuk e5-base, tapi boleh dibiarkan jika error\n",
    "    },\n",
    "    encode_kwargs={\n",
    "        'normalize_embeddings': True, # Wajib True untuk model E5 agar cosine similarity akurat\n",
    "        'batch_size': 32 # Saya naikkan dari 1. Karena tanpa kuantisasi, model ini ringan & cepat.\n",
    "    },\n",
    "    multi_process=False \n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 2: LOAD DATASET DARI EXCEL (LANGSUNG EVALUASI)\n",
    "# =====================================================\n",
    "# Ganti nama file sesuai file excel Anda yang sudah lengkap/rapi\n",
    "file_path = \"dataset_ragas_lengkap.xlsx\" \n",
    "print(f\"üìÇ Membaca file dataset: {file_path}\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# --- FUNGSI PREPROCESSING KRUSIAL ---\n",
    "# Excel menyimpan list sebagai string, contoh: \"['dokumen A', 'dokumen B']\"\n",
    "# Kita harus mengubahnya kembali menjadi list Python sungguhan: ['dokumen A', 'dokumen B']\n",
    "def parse_contexts(x):\n",
    "    if isinstance(x, list):\n",
    "        return x  # Jika sudah list, biarkan\n",
    "    try:\n",
    "        # Mencoba mengubah string representasi list menjadi list asli\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        # Jika gagal (misal sel kosong atau format rusak), kembalikan list kosong\n",
    "        return []\n",
    "\n",
    "print(\"‚öôÔ∏è Melakukan konversi format data (String -> List)...\")\n",
    "# Terapkan fungsi ke kolom contexts\n",
    "if 'contexts' in df.columns:\n",
    "    df['contexts'] = df['contexts'].apply(parse_contexts)\n",
    "else:\n",
    "    raise ValueError(\"‚ùå Kolom 'contexts' tidak ditemukan di Excel!\")\n",
    "\n",
    "# Pastikan kolom ground_truth diperlakukan sebagai string (jika ada)\n",
    "if 'ground_truth' in df.columns:\n",
    "    df['ground_truth'] = df['ground_truth'].astype(str)\n",
    "\n",
    "# Pastikan kolom answer diperlakukan sebagai string\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "\n",
    "print(\"‚úÖ Data berhasil dimuat dan diproses.\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 3: JALANKAN EVALUASI RAGAS\n",
    "# =====================================================\n",
    "# Konversi DataFrame Pandas ke Dataset RAGAs\n",
    "rag_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "metrics = [context_precision, faithfulness, answer_relevancy, context_recall]\n",
    "\n",
    "print(\"\\nüöÄ Memulai Evaluasi Ragas...\")\n",
    "# Jalankan Evaluasi\n",
    "results = evaluate(\n",
    "    dataset=rag_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "# --- PRINT HASIL AKHIR ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"üìä HASIL AKHIR SKOR RAGAS\")\n",
    "print(\"=\"*30)\n",
    "print(results)\n",
    "print(\"=\"*30)\n",
    "\n",
    "# =====================================================\n",
    "# STEP 4: SAVE HASIL KE EXCEL BARU\n",
    "# =====================================================\n",
    "metrics_df = results.to_pandas()\n",
    "\n",
    "# Reset index untuk penggabungan yang aman\n",
    "df_reset = df.reset_index(drop=True)\n",
    "metrics_reset = metrics_df.reset_index(drop=True)\n",
    "\n",
    "# Gabungkan data asli dengan skor hasil evaluasi\n",
    "final_df = pd.concat([df_reset, metrics_reset], axis=1)\n",
    "\n",
    "# Hapus kolom duplikat jika ada\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "\n",
    "# Tentukan urutan kolom yang rapi untuk output\n",
    "cols_target = ['question', 'answer', 'contexts', 'ground_truth', \n",
    "               'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "final_cols = [c for c in cols_target if c in final_df.columns]\n",
    "final_df = final_df[final_cols]\n",
    "\n",
    "output_filename = \"hasil_evaluasi_final_e5_base.xlsx\"\n",
    "final_df.to_excel(output_filename, index=False)\n",
    "print(f\"\\nüíæ File hasil evaluasi disimpan: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de82ca3",
   "metadata": {},
   "source": [
    "qwen4b dengan dataset baik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef2218f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koneksi ke Firebase Firestore berhasil.\n",
      "Inisialisasi LLM dengan model: meta-llama/llama-4-scout\n",
      "Inisialisasi Evaluator dengan model: openai/gpt-4o-mini\n",
      "üßπ VRAM Cleaned. Usage: 0.00 GB\n",
      "‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1589aa3021604c838d03980ed794b9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Membaca file dataset: dataset_ragas_lengkap.xlsx\n",
      "‚öôÔ∏è Melakukan konversi format data (String -> List)...\n",
      "‚úÖ Data berhasil dimuat dan diproses.\n",
      "\n",
      "üöÄ Memulai Evaluasi Ragas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe6ba6e74064a8d9bcdbc3490d77511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "üìä HASIL AKHIR SKOR RAGAS\n",
      "==============================\n",
      "{'context_precision': 0.8000, 'faithfulness': 0.8000, 'answer_relevancy': 0.7681, 'context_recall': 0.8000}\n",
      "==============================\n",
      "\n",
      "üíæ File hasil evaluasi disimpan: hasil_evaluasi_final.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from ast import literal_eval  # PENTING: Untuk mengubah string \"['...']\" kembali jadi list\n",
    "\n",
    "# Library Ragas & Evaluasi\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Import module custom Anda (hanya untuk evaluator judge)\n",
    "from resources import evaluator\n",
    "\n",
    "# =====================================================\n",
    "# STEP 0: BERSIHKAN MEMORI (VRAM)\n",
    "# =====================================================\n",
    "try:\n",
    "    del evaluator_embeddings\n",
    "    del results\n",
    "    del rag_dataset\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"üßπ VRAM Cleaned. Usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 1: KONFIGURASI MODEL (JUDGE & EMBEDDING)\n",
    "# =====================================================\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# LLM Judge (GPT-4o / Model Lain)\n",
    "evaluator_llm = evaluator\n",
    "\n",
    "print(\"‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\")\n",
    "evaluator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"Qwen/Qwen3-Embedding-4B\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',\n",
    "        'trust_remote_code': True,\n",
    "        'model_kwargs': {'quantization_config': bnb_config, 'device_map': 'auto'}\n",
    "    },\n",
    "    encode_kwargs={'normalize_embeddings': True, 'batch_size': 1},\n",
    "    multi_process=False \n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 2: LOAD DATASET DARI EXCEL (LANGSUNG EVALUASI)\n",
    "# =====================================================\n",
    "# Ganti nama file sesuai file excel Anda yang sudah lengkap/rapi\n",
    "file_path = \"dataset_ragas_lengkap.xlsx\" \n",
    "print(f\"üìÇ Membaca file dataset: {file_path}\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# --- FUNGSI PREPROCESSING KRUSIAL ---\n",
    "# Excel menyimpan list sebagai string, contoh: \"['dokumen A', 'dokumen B']\"\n",
    "# Kita harus mengubahnya kembali menjadi list Python sungguhan: ['dokumen A', 'dokumen B']\n",
    "def parse_contexts(x):\n",
    "    if isinstance(x, list):\n",
    "        return x  # Jika sudah list, biarkan\n",
    "    try:\n",
    "        # Mencoba mengubah string representasi list menjadi list asli\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        # Jika gagal (misal sel kosong atau format rusak), kembalikan list kosong\n",
    "        return []\n",
    "\n",
    "print(\"‚öôÔ∏è Melakukan konversi format data (String -> List)...\")\n",
    "# Terapkan fungsi ke kolom contexts\n",
    "if 'contexts' in df.columns:\n",
    "    df['contexts'] = df['contexts'].apply(parse_contexts)\n",
    "else:\n",
    "    raise ValueError(\"‚ùå Kolom 'contexts' tidak ditemukan di Excel!\")\n",
    "\n",
    "# Pastikan kolom ground_truth diperlakukan sebagai string (jika ada)\n",
    "if 'ground_truth' in df.columns:\n",
    "    df['ground_truth'] = df['ground_truth'].astype(str)\n",
    "\n",
    "# Pastikan kolom answer diperlakukan sebagai string\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "\n",
    "print(\"‚úÖ Data berhasil dimuat dan diproses.\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 3: JALANKAN EVALUASI RAGAS\n",
    "# =====================================================\n",
    "# Konversi DataFrame Pandas ke Dataset RAGAs\n",
    "rag_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "metrics = [context_precision, faithfulness, answer_relevancy, context_recall]\n",
    "\n",
    "print(\"\\nüöÄ Memulai Evaluasi Ragas...\")\n",
    "# Jalankan Evaluasi\n",
    "results = evaluate(\n",
    "    dataset=rag_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "# --- PRINT HASIL AKHIR ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"üìä HASIL AKHIR SKOR RAGAS\")\n",
    "print(\"=\"*30)\n",
    "print(results)\n",
    "print(\"=\"*30)\n",
    "\n",
    "# =====================================================\n",
    "# STEP 4: SAVE HASIL KE EXCEL BARU\n",
    "# =====================================================\n",
    "metrics_df = results.to_pandas()\n",
    "\n",
    "# Reset index untuk penggabungan yang aman\n",
    "df_reset = df.reset_index(drop=True)\n",
    "metrics_reset = metrics_df.reset_index(drop=True)\n",
    "\n",
    "# Gabungkan data asli dengan skor hasil evaluasi\n",
    "final_df = pd.concat([df_reset, metrics_reset], axis=1)\n",
    "\n",
    "# Hapus kolom duplikat jika ada\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "\n",
    "# Tentukan urutan kolom yang rapi untuk output\n",
    "cols_target = ['question', 'answer', 'contexts', 'ground_truth', \n",
    "               'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "final_cols = [c for c in cols_target if c in final_df.columns]\n",
    "final_df = final_df[final_cols]\n",
    "\n",
    "output_filename = \"hasil_evaluasi_final.xlsx\"\n",
    "final_df.to_excel(output_filename, index=False)\n",
    "print(f\"\\nüíæ File hasil evaluasi disimpan: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f98e943",
   "metadata": {},
   "source": [
    "e5 dengan dataset baik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8998e154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ VRAM Cleaned. Usage: 0.01 GB\n",
      "‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\n",
      "üìÇ Membaca file dataset: dataset_ragas_lengkap.xlsx\n",
      "‚öôÔ∏è Melakukan konversi format data (String -> List)...\n",
      "‚úÖ Data berhasil dimuat dan diproses.\n",
      "\n",
      "üöÄ Memulai Evaluasi Ragas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d92139764ab410192bc838414bb716d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "üìä HASIL AKHIR SKOR RAGAS\n",
      "==============================\n",
      "{'context_precision': 0.8500, 'faithfulness': 0.8000, 'answer_relevancy': 0.9155, 'context_recall': 0.8000}\n",
      "==============================\n",
      "\n",
      "üíæ File hasil evaluasi disimpan: hasil_evaluasi_final_e5_base.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from ast import literal_eval  # PENTING: Untuk mengubah string \"['...']\" kembali jadi list\n",
    "from resources import evaluator\n",
    "evaluator_llm = evaluator\n",
    "\n",
    "# Library Ragas & Evaluasi\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Import module custom Anda (hanya untuk evaluator judge)\n",
    "from resources import evaluator\n",
    "\n",
    "# =====================================================\n",
    "# STEP 0: BERSIHKAN MEMORI (VRAM)\n",
    "# =====================================================\n",
    "try:\n",
    "    del evaluator_embeddings\n",
    "    del results\n",
    "    del rag_dataset\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"üßπ VRAM Cleaned. Usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 1: KONFIGURASI MODEL (JUDGE & EMBEDDING)\n",
    "# =====================================================\n",
    "print(\"‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\")\n",
    "\n",
    "evaluator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',   # Memaksa model berjalan di GPU\n",
    "        # 'trust_remote_code': True # Biasanya tidak wajib untuk e5-base, tapi boleh dibiarkan jika error\n",
    "    },\n",
    "    encode_kwargs={\n",
    "        'normalize_embeddings': True, # Wajib True untuk model E5 agar cosine similarity akurat\n",
    "        'batch_size': 32 # Saya naikkan dari 1. Karena tanpa kuantisasi, model ini ringan & cepat.\n",
    "    },\n",
    "    multi_process=False \n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 2: LOAD DATASET DARI EXCEL (LANGSUNG EVALUASI)\n",
    "# =====================================================\n",
    "# Ganti nama file sesuai file excel Anda yang sudah lengkap/rapi\n",
    "file_path = \"dataset_ragas_lengkap.xlsx\" \n",
    "print(f\"üìÇ Membaca file dataset: {file_path}\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# --- FUNGSI PREPROCESSING KRUSIAL ---\n",
    "# Excel menyimpan list sebagai string, contoh: \"['dokumen A', 'dokumen B']\"\n",
    "# Kita harus mengubahnya kembali menjadi list Python sungguhan: ['dokumen A', 'dokumen B']\n",
    "def parse_contexts(x):\n",
    "    if isinstance(x, list):\n",
    "        return x  # Jika sudah list, biarkan\n",
    "    try:\n",
    "        # Mencoba mengubah string representasi list menjadi list asli\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        # Jika gagal (misal sel kosong atau format rusak), kembalikan list kosong\n",
    "        return []\n",
    "\n",
    "print(\"‚öôÔ∏è Melakukan konversi format data (String -> List)...\")\n",
    "# Terapkan fungsi ke kolom contexts\n",
    "if 'contexts' in df.columns:\n",
    "    df['contexts'] = df['contexts'].apply(parse_contexts)\n",
    "else:\n",
    "    raise ValueError(\"‚ùå Kolom 'contexts' tidak ditemukan di Excel!\")\n",
    "\n",
    "# Pastikan kolom ground_truth diperlakukan sebagai string (jika ada)\n",
    "if 'ground_truth' in df.columns:\n",
    "    df['ground_truth'] = df['ground_truth'].astype(str)\n",
    "\n",
    "# Pastikan kolom answer diperlakukan sebagai string\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "\n",
    "print(\"‚úÖ Data berhasil dimuat dan diproses.\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 3: JALANKAN EVALUASI RAGAS\n",
    "# =====================================================\n",
    "# Konversi DataFrame Pandas ke Dataset RAGAs\n",
    "rag_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "metrics = [context_precision, faithfulness, answer_relevancy, context_recall]\n",
    "\n",
    "print(\"\\nüöÄ Memulai Evaluasi Ragas...\")\n",
    "# Jalankan Evaluasi\n",
    "results = evaluate(\n",
    "    dataset=rag_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "# --- PRINT HASIL AKHIR ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"üìä HASIL AKHIR SKOR RAGAS\")\n",
    "print(\"=\"*30)\n",
    "print(results)\n",
    "print(\"=\"*30)\n",
    "\n",
    "# =====================================================\n",
    "# STEP 4: SAVE HASIL KE EXCEL BARU\n",
    "# =====================================================\n",
    "metrics_df = results.to_pandas()\n",
    "\n",
    "# Reset index untuk penggabungan yang aman\n",
    "df_reset = df.reset_index(drop=True)\n",
    "metrics_reset = metrics_df.reset_index(drop=True)\n",
    "\n",
    "# Gabungkan data asli dengan skor hasil evaluasi\n",
    "final_df = pd.concat([df_reset, metrics_reset], axis=1)\n",
    "\n",
    "# Hapus kolom duplikat jika ada\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "\n",
    "# Tentukan urutan kolom yang rapi untuk output\n",
    "cols_target = ['question', 'answer', 'contexts', 'ground_truth', \n",
    "               'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "final_cols = [c for c in cols_target if c in final_df.columns]\n",
    "final_df = final_df[final_cols]\n",
    "\n",
    "output_filename = \"hasil_evaluasi_final_e5_base.xlsx\"\n",
    "final_df.to_excel(output_filename, index=False)\n",
    "print(f\"\\nüíæ File hasil evaluasi disimpan: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9057096",
   "metadata": {},
   "source": [
    "qwen 0.6b dataset baik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48bba53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ VRAM Cleaned. Usage: 0.01 GB\n",
      "‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\n",
      "üìÇ Membaca file dataset: dataset_ragas_lengkap.xlsx\n",
      "‚öôÔ∏è Melakukan konversi format data (String -> List)...\n",
      "‚úÖ Data berhasil dimuat dan diproses.\n",
      "\n",
      "üöÄ Memulai Evaluasi Ragas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7de95e2559b410f8784a2601cd2a68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "üìä HASIL AKHIR SKOR RAGAS\n",
      "==============================\n",
      "{'context_precision': 0.8500, 'faithfulness': 0.8000, 'answer_relevancy': 0.7532, 'context_recall': 0.8000}\n",
      "==============================\n",
      "\n",
      "üíæ File hasil evaluasi disimpan: hasil_evaluasi_final_e5_base.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from ast import literal_eval  # PENTING: Untuk mengubah string \"['...']\" kembali jadi list\n",
    "from resources import evaluator\n",
    "evaluator_llm = evaluator\n",
    "\n",
    "# Library Ragas & Evaluasi\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Import module custom Anda (hanya untuk evaluator judge)\n",
    "from resources import evaluator\n",
    "\n",
    "# =====================================================\n",
    "# STEP 0: BERSIHKAN MEMORI (VRAM)\n",
    "# =====================================================\n",
    "try:\n",
    "    del evaluator_embeddings\n",
    "    del results\n",
    "    del rag_dataset\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"üßπ VRAM Cleaned. Usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 1: KONFIGURASI MODEL (JUDGE & EMBEDDING)\n",
    "# =====================================================\n",
    "print(\"‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\")\n",
    "\n",
    "evaluator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"Qwen/Qwen3-Embedding-0.6B\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',   # Memaksa model berjalan di GPU\n",
    "        # 'trust_remote_code': True # Biasanya tidak wajib untuk e5-base, tapi boleh dibiarkan jika error\n",
    "    },\n",
    "    encode_kwargs={\n",
    "        'normalize_embeddings': True, # Wajib True untuk model E5 agar cosine similarity akurat\n",
    "        'batch_size': 32 # Saya naikkan dari 1. Karena tanpa kuantisasi, model ini ringan & cepat.\n",
    "    },\n",
    "    multi_process=False \n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 2: LOAD DATASET DARI EXCEL (LANGSUNG EVALUASI)\n",
    "# =====================================================\n",
    "# Ganti nama file sesuai file excel Anda yang sudah lengkap/rapi\n",
    "file_path = \"dataset_ragas_lengkap.xlsx\" \n",
    "print(f\"üìÇ Membaca file dataset: {file_path}\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# --- FUNGSI PREPROCESSING KRUSIAL ---\n",
    "# Excel menyimpan list sebagai string, contoh: \"['dokumen A', 'dokumen B']\"\n",
    "# Kita harus mengubahnya kembali menjadi list Python sungguhan: ['dokumen A', 'dokumen B']\n",
    "def parse_contexts(x):\n",
    "    if isinstance(x, list):\n",
    "        return x  # Jika sudah list, biarkan\n",
    "    try:\n",
    "        # Mencoba mengubah string representasi list menjadi list asli\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        # Jika gagal (misal sel kosong atau format rusak), kembalikan list kosong\n",
    "        return []\n",
    "\n",
    "print(\"‚öôÔ∏è Melakukan konversi format data (String -> List)...\")\n",
    "# Terapkan fungsi ke kolom contexts\n",
    "if 'contexts' in df.columns:\n",
    "    df['contexts'] = df['contexts'].apply(parse_contexts)\n",
    "else:\n",
    "    raise ValueError(\"‚ùå Kolom 'contexts' tidak ditemukan di Excel!\")\n",
    "\n",
    "# Pastikan kolom ground_truth diperlakukan sebagai string (jika ada)\n",
    "if 'ground_truth' in df.columns:\n",
    "    df['ground_truth'] = df['ground_truth'].astype(str)\n",
    "\n",
    "# Pastikan kolom answer diperlakukan sebagai string\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "\n",
    "print(\"‚úÖ Data berhasil dimuat dan diproses.\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 3: JALANKAN EVALUASI RAGAS\n",
    "# =====================================================\n",
    "# Konversi DataFrame Pandas ke Dataset RAGAs\n",
    "rag_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "metrics = [context_precision, faithfulness, answer_relevancy, context_recall]\n",
    "\n",
    "print(\"\\nüöÄ Memulai Evaluasi Ragas...\")\n",
    "# Jalankan Evaluasi\n",
    "results = evaluate(\n",
    "    dataset=rag_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "# --- PRINT HASIL AKHIR ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"üìä HASIL AKHIR SKOR RAGAS\")\n",
    "print(\"=\"*30)\n",
    "print(results)\n",
    "print(\"=\"*30)\n",
    "\n",
    "# =====================================================\n",
    "# STEP 4: SAVE HASIL KE EXCEL BARU\n",
    "# =====================================================\n",
    "metrics_df = results.to_pandas()\n",
    "\n",
    "# Reset index untuk penggabungan yang aman\n",
    "df_reset = df.reset_index(drop=True)\n",
    "metrics_reset = metrics_df.reset_index(drop=True)\n",
    "\n",
    "# Gabungkan data asli dengan skor hasil evaluasi\n",
    "final_df = pd.concat([df_reset, metrics_reset], axis=1)\n",
    "\n",
    "# Hapus kolom duplikat jika ada\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "\n",
    "# Tentukan urutan kolom yang rapi untuk output\n",
    "cols_target = ['question', 'answer', 'contexts', 'ground_truth', \n",
    "               'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "final_cols = [c for c in cols_target if c in final_df.columns]\n",
    "final_df = final_df[final_cols]\n",
    "\n",
    "output_filename = \"hasil_evaluasi_final_e5_base.xlsx\"\n",
    "final_df.to_excel(output_filename, index=False)\n",
    "print(f\"\\nüíæ File hasil evaluasi disimpan: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4d04ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koneksi ke Firebase Firestore berhasil.\n",
      "Inisialisasi LLM dengan model: meta-llama/llama-4-scout\n",
      "Inisialisasi Evaluator dengan model: openai/gpt-4o-mini\n",
      "üßπ VRAM Cleaned. Usage: 0.00 GB\n",
      "‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\n",
      "üìÇ Membaca file dataset: dataset_ragas_lengkap.xlsx\n",
      "‚öôÔ∏è Melakukan konversi format data (String -> List)...\n",
      "‚úÖ Data berhasil dimuat dan diproses.\n",
      "\n",
      "üöÄ Memulai Evaluasi Ragas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5570d7bef7b24643a1de230cd796e22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "üìä HASIL AKHIR SKOR RAGAS\n",
      "==============================\n",
      "{'context_precision': 0.8889, 'faithfulness': 0.8889, 'answer_relevancy': 0.9067, 'context_recall': 0.8889}\n",
      "==============================\n",
      "\n",
      "üíæ File hasil evaluasi disimpan: hasil_evaluasi_final_e5_base.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from ast import literal_eval  # PENTING: Untuk mengubah string \"['...']\" kembali jadi list\n",
    "from resources import evaluator\n",
    "evaluator_llm = evaluator\n",
    "\n",
    "# Library Ragas & Evaluasi\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Import module custom Anda (hanya untuk evaluator judge)\n",
    "from resources import evaluator\n",
    "\n",
    "# =====================================================\n",
    "# STEP 0: BERSIHKAN MEMORI (VRAM)\n",
    "# =====================================================\n",
    "try:\n",
    "    del evaluator_embeddings\n",
    "    del results\n",
    "    del rag_dataset\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"üßπ VRAM Cleaned. Usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 1: KONFIGURASI MODEL (JUDGE & EMBEDDING)\n",
    "# =====================================================\n",
    "print(\"‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\")\n",
    "\n",
    "evaluator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',   # Memaksa model berjalan di GPU\n",
    "        # 'trust_remote_code': True # Biasanya tidak wajib untuk e5-base, tapi boleh dibiarkan jika error\n",
    "    },\n",
    "    encode_kwargs={\n",
    "        'normalize_embeddings': True, # Wajib True untuk model E5 agar cosine similarity akurat\n",
    "        'batch_size': 32 # Saya naikkan dari 1. Karena tanpa kuantisasi, model ini ringan & cepat.\n",
    "    },\n",
    "    multi_process=False \n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 2: LOAD DATASET DARI EXCEL (LANGSUNG EVALUASI)\n",
    "# =====================================================\n",
    "# Ganti nama file sesuai file excel Anda yang sudah lengkap/rapi\n",
    "file_path = \"dataset_ragas_lengkap.xlsx\" \n",
    "print(f\"üìÇ Membaca file dataset: {file_path}\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# --- FUNGSI PREPROCESSING KRUSIAL ---\n",
    "# Excel menyimpan list sebagai string, contoh: \"['dokumen A', 'dokumen B']\"\n",
    "# Kita harus mengubahnya kembali menjadi list Python sungguhan: ['dokumen A', 'dokumen B']\n",
    "def parse_contexts(x):\n",
    "    if isinstance(x, list):\n",
    "        return x  # Jika sudah list, biarkan\n",
    "    try:\n",
    "        # Mencoba mengubah string representasi list menjadi list asli\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        # Jika gagal (misal sel kosong atau format rusak), kembalikan list kosong\n",
    "        return []\n",
    "\n",
    "print(\"‚öôÔ∏è Melakukan konversi format data (String -> List)...\")\n",
    "# Terapkan fungsi ke kolom contexts\n",
    "if 'contexts' in df.columns:\n",
    "    df['contexts'] = df['contexts'].apply(parse_contexts)\n",
    "else:\n",
    "    raise ValueError(\"‚ùå Kolom 'contexts' tidak ditemukan di Excel!\")\n",
    "\n",
    "# Pastikan kolom ground_truth diperlakukan sebagai string (jika ada)\n",
    "if 'ground_truth' in df.columns:\n",
    "    df['ground_truth'] = df['ground_truth'].astype(str)\n",
    "\n",
    "# Pastikan kolom answer diperlakukan sebagai string\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "\n",
    "print(\"‚úÖ Data berhasil dimuat dan diproses.\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 3: JALANKAN EVALUASI RAGAS\n",
    "# =====================================================\n",
    "# Konversi DataFrame Pandas ke Dataset RAGAs\n",
    "rag_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "metrics = [context_precision, faithfulness, answer_relevancy, context_recall]\n",
    "\n",
    "print(\"\\nüöÄ Memulai Evaluasi Ragas...\")\n",
    "# Jalankan Evaluasi\n",
    "results = evaluate(\n",
    "    dataset=rag_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "# --- PRINT HASIL AKHIR ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"üìä HASIL AKHIR SKOR RAGAS\")\n",
    "print(\"=\"*30)\n",
    "print(results)\n",
    "print(\"=\"*30)\n",
    "\n",
    "# =====================================================\n",
    "# STEP 4: SAVE HASIL KE EXCEL BARU\n",
    "# =====================================================\n",
    "metrics_df = results.to_pandas()\n",
    "\n",
    "# Reset index untuk penggabungan yang aman\n",
    "df_reset = df.reset_index(drop=True)\n",
    "metrics_reset = metrics_df.reset_index(drop=True)\n",
    "\n",
    "# Gabungkan data asli dengan skor hasil evaluasi\n",
    "final_df = pd.concat([df_reset, metrics_reset], axis=1)\n",
    "\n",
    "# Hapus kolom duplikat jika ada\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "\n",
    "# Tentukan urutan kolom yang rapi untuk output\n",
    "cols_target = ['question', 'answer', 'contexts', 'ground_truth', \n",
    "               'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "final_cols = [c for c in cols_target if c in final_df.columns]\n",
    "final_df = final_df[final_cols]\n",
    "\n",
    "output_filename = \"hasil_evaluasi_final_e5_base.xlsx\"\n",
    "final_df.to_excel(output_filename, index=False)\n",
    "print(f\"\\nüíæ File hasil evaluasi disimpan: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5616a7",
   "metadata": {},
   "source": [
    "uji dengan 130 QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e9c5ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koneksi ke Firebase Firestore berhasil.\n",
      "Inisialisasi LLM dengan model: meta-llama/llama-4-scout\n",
      "Menggunakan model evaluator UPATIK\n",
      "Inisialisasi Evaluator dengan model: gpt-4o-mini\n",
      "üßπ VRAM Cleaned. Usage: 0.00 GB\n",
      "‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\n",
      "üìÇ Membaca file dataset: dataset_ragas_lengkap.xlsx\n",
      "‚öôÔ∏è Melakukan konversi format data (String -> List)...\n",
      "‚úÖ Data berhasil dimuat dan diproses.\n",
      "\n",
      "üöÄ Memulai Evaluasi Ragas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f785922a673441b2ae60d0d25f4ef4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "üìä HASIL AKHIR SKOR RAGAS\n",
      "==============================\n",
      "{'context_precision': 0.8833, 'faithfulness': 0.7517, 'answer_relevancy': 0.8989, 'context_recall': 0.9231}\n",
      "==============================\n",
      "\n",
      "üíæ File hasil evaluasi disimpan: hasil_evaluasi_final_e5_base.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from ast import literal_eval  # PENTING: Untuk mengubah string \"['...']\" kembali jadi list\n",
    "from resources import evaluator\n",
    "evaluator_llm = evaluator\n",
    "\n",
    "# Library Ragas & Evaluasi\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Import module custom Anda (hanya untuk evaluator judge)\n",
    "from resources import evaluator\n",
    "\n",
    "# =====================================================\n",
    "# STEP 0: BERSIHKAN MEMORI (VRAM)\n",
    "# =====================================================\n",
    "try:\n",
    "    del evaluator_embeddings\n",
    "    del results\n",
    "    del rag_dataset\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"üßπ VRAM Cleaned. Usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 1: KONFIGURASI MODEL (JUDGE & EMBEDDING)\n",
    "# =====================================================\n",
    "print(\"‚öôÔ∏è Loading Embedding Model (untuk metrik Ragas)...\")\n",
    "\n",
    "evaluator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',   # Memaksa model berjalan di GPU\n",
    "        # 'trust_remote_code': True # Biasanya tidak wajib untuk e5-base, tapi boleh dibiarkan jika error\n",
    "    },\n",
    "    encode_kwargs={\n",
    "        'normalize_embeddings': True, # Wajib True untuk model E5 agar cosine similarity akurat\n",
    "        'batch_size': 32 # Saya naikkan dari 1. Karena tanpa kuantisasi, model ini ringan & cepat.\n",
    "    },\n",
    "    multi_process=False \n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 2: LOAD DATASET DARI EXCEL (LANGSUNG EVALUASI)\n",
    "# =====================================================\n",
    "# Ganti nama file sesuai file excel Anda yang sudah lengkap/rapi\n",
    "file_path = \"dataset_ragas_lengkap.xlsx\" \n",
    "print(f\"üìÇ Membaca file dataset: {file_path}\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# --- FUNGSI PREPROCESSING KRUSIAL ---\n",
    "# Excel menyimpan list sebagai string, contoh: \"['dokumen A', 'dokumen B']\"\n",
    "# Kita harus mengubahnya kembali menjadi list Python sungguhan: ['dokumen A', 'dokumen B']\n",
    "def parse_contexts(x):\n",
    "    if isinstance(x, list):\n",
    "        return x  # Jika sudah list, biarkan\n",
    "    try:\n",
    "        # Mencoba mengubah string representasi list menjadi list asli\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        # Jika gagal (misal sel kosong atau format rusak), kembalikan list kosong\n",
    "        return []\n",
    "\n",
    "print(\"‚öôÔ∏è Melakukan konversi format data (String -> List)...\")\n",
    "# Terapkan fungsi ke kolom contexts\n",
    "if 'contexts' in df.columns:\n",
    "    df['contexts'] = df['contexts'].apply(parse_contexts)\n",
    "else:\n",
    "    raise ValueError(\"‚ùå Kolom 'contexts' tidak ditemukan di Excel!\")\n",
    "\n",
    "# Pastikan kolom ground_truth diperlakukan sebagai string (jika ada)\n",
    "if 'ground_truth' in df.columns:\n",
    "    df['ground_truth'] = df['ground_truth'].astype(str)\n",
    "\n",
    "# Pastikan kolom answer diperlakukan sebagai string\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "\n",
    "print(\"‚úÖ Data berhasil dimuat dan diproses.\")\n",
    "\n",
    "# =====================================================\n",
    "# STEP 3: JALANKAN EVALUASI RAGAS\n",
    "# =====================================================\n",
    "# Konversi DataFrame Pandas ke Dataset RAGAs\n",
    "rag_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "metrics = [context_precision, faithfulness, answer_relevancy, context_recall]\n",
    "\n",
    "print(\"\\nüöÄ Memulai Evaluasi Ragas...\")\n",
    "# Jalankan Evaluasi\n",
    "results = evaluate(\n",
    "    dataset=rag_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "# --- PRINT HASIL AKHIR ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"üìä HASIL AKHIR SKOR RAGAS\")\n",
    "print(\"=\"*30)\n",
    "print(results)\n",
    "print(\"=\"*30)\n",
    "\n",
    "# =====================================================\n",
    "# STEP 4: SAVE HASIL KE EXCEL BARU\n",
    "# =====================================================\n",
    "metrics_df = results.to_pandas()\n",
    "\n",
    "# Reset index untuk penggabungan yang aman\n",
    "df_reset = df.reset_index(drop=True)\n",
    "metrics_reset = metrics_df.reset_index(drop=True)\n",
    "\n",
    "# Gabungkan data asli dengan skor hasil evaluasi\n",
    "final_df = pd.concat([df_reset, metrics_reset], axis=1)\n",
    "\n",
    "# Hapus kolom duplikat jika ada\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "\n",
    "# Tentukan urutan kolom yang rapi untuk output\n",
    "cols_target = ['question', 'answer', 'contexts', 'ground_truth', \n",
    "               'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "final_cols = [c for c in cols_target if c in final_df.columns]\n",
    "final_df = final_df[final_cols]\n",
    "\n",
    "output_filename = \"hasil_evaluasi_final_e5_base.xlsx\"\n",
    "final_df.to_excel(output_filename, index=False)\n",
    "print(f\"\\nüíæ File hasil evaluasi disimpan: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea63ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
