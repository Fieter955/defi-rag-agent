{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5616a7",
   "metadata": {},
   "source": [
    "uji dengan 130 QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c5ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koneksi ke Firebase Firestore berhasil.\n",
      "Inisialisasi LLM dengan model: meta-llama/llama-4-scout\n",
      "Menggunakan model evaluator UPATIK\n",
      "Inisialisasi Evaluator dengan model: gpt-4o-mini\n",
      "ðŸ§¹ VRAM Cleaned. Usage: 0.00 GB\n",
      "âš™ï¸ Loading Embedding Model (untuk metrik Ragas)...\n",
      "ðŸ“‚ Membaca file dataset: dataset_ragas_lengkap.xlsx\n",
      "âš™ï¸ Melakukan konversi format data (String -> List)...\n",
      "âœ… Data berhasil dimuat dan diproses.\n",
      "\n",
      "ðŸš€ Memulai Evaluasi Ragas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f785922a673441b2ae60d0d25f4ef4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ðŸ“Š HASIL AKHIR SKOR RAGAS\n",
      "==============================\n",
      "{'context_precision': 0.8833, 'faithfulness': 0.7517, 'answer_relevancy': 0.8989, 'context_recall': 0.9231}\n",
      "==============================\n",
      "\n",
      "ðŸ’¾ File hasil evaluasi disimpan: hasil_evaluasi_final_e5_base.xlsx\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from ast import literal_eval\n",
    "from resources import evaluator\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import BitsAndBytesConfig\n",
    "from resources import evaluator\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "evaluator_llm = evaluator\n",
    "# STEP 0: BERSIHKAN MEMORI (VRAM)\n",
    "try:\n",
    "    del evaluator_embeddings\n",
    "    del results\n",
    "    del rag_dataset\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"VRAM Cleaned. Usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# STEP 1: KONFIGURASI MODEL (JUDGE & EMBEDDING)\n",
    "print(\"Loading Embedding Model (untuk metrik Ragas)...\")\n",
    "\n",
    "evaluator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',\n",
    "\n",
    "    },\n",
    "    encode_kwargs={\n",
    "        'normalize_embeddings': True,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    multi_process=False \n",
    ")\n",
    "\n",
    "# STEP 2: LOAD DATASET DARI EXCEL (LANGSUNG EVALUASI)\n",
    "file_path = \"dataset_ragas_lengkap.xlsx\" \n",
    "print(f\"Membaca file dataset: {file_path}\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "def parse_contexts(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    try:\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "print(\"Melakukan konversi format data (String -> List)...\")\n",
    "if 'contexts' in df.columns:\n",
    "    df['contexts'] = df['contexts'].apply(parse_contexts)\n",
    "else:\n",
    "    raise ValueError(\"Kolom 'contexts' tidak ditemukan di Excel!\")\n",
    "if 'ground_truth' in df.columns:\n",
    "    df['ground_truth'] = df['ground_truth'].astype(str)\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "print(\"Data berhasil dimuat dan diproses.\")\n",
    "\n",
    "\n",
    "# STEP 3: JALANKAN EVALUASI RAGAS\n",
    "rag_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "metrics = [context_precision, faithfulness, answer_relevancy, context_recall]\n",
    "\n",
    "print(\"\\nMemulai Evaluasi Ragas...\")\n",
    "# Jalankan Evaluasi\n",
    "results = evaluate(\n",
    "    dataset=rag_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"HASIL AKHIR SKOR RAGAS\")\n",
    "print(\"=\"*30)\n",
    "print(results)\n",
    "print(\"=\"*30)\n",
    "\n",
    "\n",
    "# STEP 4: SAVE HASIL KE EXCEL BARU\n",
    "metrics_df = results.to_pandas()\n",
    "\n",
    "df_reset = df.reset_index(drop=True)\n",
    "metrics_reset = metrics_df.reset_index(drop=True)\n",
    "final_df = pd.concat([df_reset, metrics_reset], axis=1)\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "cols_target = ['question', 'answer', 'contexts', 'ground_truth', \n",
    "               'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "final_cols = [c for c in cols_target if c in final_df.columns]\n",
    "final_df = final_df[final_cols]\n",
    "output_filename = \"hasil_evaluasi_final_e5_base.xlsx\"\n",
    "final_df.to_excel(output_filename, index=False)\n",
    "print(f\"\\nFile hasil evaluasi disimpan: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83072ac9",
   "metadata": {},
   "source": [
    "130 QA Gemma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "078c8ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koneksi ke Firebase Firestore berhasil.\n",
      "Inisialisasi LLM dengan model: meta-llama/llama-4-scout-17b-16e-instruct\n",
      "Inisialisasi Evaluator dengan model: gpt-4o-mini\n",
      "VRAM Cleaned. Usage: 0.00 GB\n",
      "Loading Embedding Model (untuk metrik Ragas)...\n",
      "Membaca file dataset: .//dataset//preprocessed//gemma.xlsx\n",
      "Melakukan konversi format data (String -> List)...\n",
      "Data berhasil dimuat dan diproses.\n",
      "\n",
      "Memulai Evaluasi Ragas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785f48ab40094e8ea4af1a95e011ff68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "HASIL AKHIR SKOR RAGAS\n",
      "==============================\n",
      "{'context_precision': 0.8946, 'faithfulness': 0.7792, 'answer_relevancy': 0.9033, 'context_recall': 0.9314}\n",
      "==============================\n",
      "\n",
      "File hasil evaluasi disimpan: .//dataset//result//gemma.xlsx\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from ast import literal_eval\n",
    "from resources import evaluator\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import BitsAndBytesConfig\n",
    "from resources import evaluator\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "input_dir = \".//dataset//preprocessed//gemma.xlsx\"\n",
    "output_dir = \".//dataset//result//gemma.xlsx\"\n",
    "\n",
    "evaluator_llm = evaluator\n",
    "# STEP 0: BERSIHKAN MEMORI (VRAM)\n",
    "try:\n",
    "    del evaluator_embeddings\n",
    "    del results\n",
    "    del rag_dataset\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"VRAM Cleaned. Usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# STEP 1: KONFIGURASI MODEL (JUDGE & EMBEDDING)\n",
    "print(\"Loading Embedding Model (untuk metrik Ragas)...\")\n",
    "\n",
    "evaluator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',\n",
    "\n",
    "    },\n",
    "    encode_kwargs={\n",
    "        'normalize_embeddings': True,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    multi_process=False \n",
    ")\n",
    "\n",
    "# STEP 2: LOAD DATASET DARI EXCEL (LANGSUNG EVALUASI)\n",
    "file_path = input_dir \n",
    "print(f\"Membaca file dataset: {file_path}\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "def parse_contexts(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    try:\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "print(\"Melakukan konversi format data (String -> List)...\")\n",
    "if 'contexts' in df.columns:\n",
    "    df['contexts'] = df['contexts'].apply(parse_contexts)\n",
    "else:\n",
    "    raise ValueError(\"Kolom 'contexts' tidak ditemukan di Excel!\")\n",
    "if 'ground_truth' in df.columns:\n",
    "    df['ground_truth'] = df['ground_truth'].astype(str)\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "print(\"Data berhasil dimuat dan diproses.\")\n",
    "\n",
    "\n",
    "# STEP 3: JALANKAN EVALUASI RAGAS\n",
    "rag_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "metrics = [context_precision, faithfulness, answer_relevancy, context_recall]\n",
    "\n",
    "print(\"\\nMemulai Evaluasi Ragas...\")\n",
    "# Jalankan Evaluasi\n",
    "results = evaluate(\n",
    "    dataset=rag_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"HASIL AKHIR SKOR RAGAS\")\n",
    "print(\"=\"*30)\n",
    "print(results)\n",
    "print(\"=\"*30)\n",
    "\n",
    "\n",
    "# STEP 4: SAVE HASIL KE EXCEL BARU\n",
    "metrics_df = results.to_pandas()\n",
    "\n",
    "df_reset = df.reset_index(drop=True)\n",
    "metrics_reset = metrics_df.reset_index(drop=True)\n",
    "final_df = pd.concat([df_reset, metrics_reset], axis=1)\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "cols_target = ['question', 'answer', 'contexts', 'ground_truth', \n",
    "               'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "final_cols = [c for c in cols_target if c in final_df.columns]\n",
    "final_df = final_df[final_cols]\n",
    "output_filename = output_dir\n",
    "final_df.to_excel(output_filename, index=False)\n",
    "print(f\"\\nFile hasil evaluasi disimpan: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485d7ae5",
   "metadata": {},
   "source": [
    "130 QA llama scout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "130ea917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRAM Cleaned. Usage: 0.01 GB\n",
      "Loading Embedding Model (untuk metrik Ragas)...\n",
      "Membaca file dataset: .//dataset//preprocessed//llama4scout.xlsx\n",
      "Melakukan konversi format data (String -> List)...\n",
      "Data berhasil dimuat dan diproses.\n",
      "\n",
      "Memulai Evaluasi Ragas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e4b2b67ad14cf78b08fd91c9beba85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "HASIL AKHIR SKOR RAGAS\n",
      "==============================\n",
      "{'context_precision': 0.8915, 'faithfulness': 0.8084, 'answer_relevancy': 0.9034, 'context_recall': 0.9603}\n",
      "==============================\n",
      "\n",
      "File hasil evaluasi disimpan: .//dataset//result//llama4scout.xlsx\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from ast import literal_eval\n",
    "from resources import evaluator\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import BitsAndBytesConfig\n",
    "from resources import evaluator\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "input_dir = \".//dataset//preprocessed//llama4scout.xlsx\"\n",
    "output_dir = \".//dataset//result//llama4scout.xlsx\"\n",
    "\n",
    "evaluator_llm = evaluator\n",
    "# STEP 0: BERSIHKAN MEMORI (VRAM)\n",
    "try:\n",
    "    del evaluator_embeddings\n",
    "    del results\n",
    "    del rag_dataset\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"VRAM Cleaned. Usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# STEP 1: KONFIGURASI MODEL (JUDGE & EMBEDDING)\n",
    "print(\"Loading Embedding Model (untuk metrik Ragas)...\")\n",
    "\n",
    "evaluator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',\n",
    "\n",
    "    },\n",
    "    encode_kwargs={\n",
    "        'normalize_embeddings': True,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    multi_process=False \n",
    ")\n",
    "\n",
    "# STEP 2: LOAD DATASET DARI EXCEL (LANGSUNG EVALUASI)\n",
    "file_path = input_dir \n",
    "print(f\"Membaca file dataset: {file_path}\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "def parse_contexts(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    try:\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "print(\"Melakukan konversi format data (String -> List)...\")\n",
    "if 'contexts' in df.columns:\n",
    "    df['contexts'] = df['contexts'].apply(parse_contexts)\n",
    "else:\n",
    "    raise ValueError(\"Kolom 'contexts' tidak ditemukan di Excel!\")\n",
    "if 'ground_truth' in df.columns:\n",
    "    df['ground_truth'] = df['ground_truth'].astype(str)\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "print(\"Data berhasil dimuat dan diproses.\")\n",
    "\n",
    "\n",
    "# STEP 3: JALANKAN EVALUASI RAGAS\n",
    "rag_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "metrics = [context_precision, faithfulness, answer_relevancy, context_recall]\n",
    "\n",
    "print(\"\\nMemulai Evaluasi Ragas...\")\n",
    "# Jalankan Evaluasi\n",
    "results = evaluate(\n",
    "    dataset=rag_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"HASIL AKHIR SKOR RAGAS\")\n",
    "print(\"=\"*30)\n",
    "print(results)\n",
    "print(\"=\"*30)\n",
    "\n",
    "\n",
    "# STEP 4: SAVE HASIL KE EXCEL BARU\n",
    "metrics_df = results.to_pandas()\n",
    "\n",
    "df_reset = df.reset_index(drop=True)\n",
    "metrics_reset = metrics_df.reset_index(drop=True)\n",
    "final_df = pd.concat([df_reset, metrics_reset], axis=1)\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "cols_target = ['question', 'answer', 'contexts', 'ground_truth', \n",
    "               'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "final_cols = [c for c in cols_target if c in final_df.columns]\n",
    "final_df = final_df[final_cols]\n",
    "output_filename = output_dir\n",
    "final_df.to_excel(output_filename, index=False)\n",
    "print(f\"\\nFile hasil evaluasi disimpan: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adf4035",
   "metadata": {},
   "source": [
    "130 QA llma4 rerangker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a1a56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRAM Cleaned. Usage: 0.01 GB\n",
      "Loading Embedding Model (untuk metrik Ragas)...\n",
      "Membaca file dataset: .//dataset//preprocessed//llama4scout_rerangker.xlsx\n",
      "Melakukan konversi format data (String -> List)...\n",
      "Data berhasil dimuat dan diproses.\n",
      "\n",
      "Memulai Evaluasi Ragas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0e4abfff4842c58cdac91e559fbb09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "HASIL AKHIR SKOR RAGAS\n",
      "==============================\n",
      "{'context_precision': 0.9340, 'faithfulness': 0.8353, 'answer_relevancy': 0.9006, 'context_recall': 0.9769}\n",
      "==============================\n",
      "\n",
      "File hasil evaluasi disimpan: .//dataset//result//llama4scout_rerangker.xlsx\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from ast import literal_eval\n",
    "from resources import evaluator\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import BitsAndBytesConfig\n",
    "from resources import evaluator\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "input_dir = \".//dataset//preprocessed//llama4scout_rerangker.xlsx\"\n",
    "output_dir = \".//dataset//result//llama4scout_rerangker.xlsx\"\n",
    "\n",
    "evaluator_llm = evaluator\n",
    "# STEP 0: BERSIHKAN MEMORI (VRAM)\n",
    "try:\n",
    "    del evaluator_embeddings\n",
    "    del results\n",
    "    del rag_dataset\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"VRAM Cleaned. Usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# STEP 1: KONFIGURASI MODEL (JUDGE & EMBEDDING)\n",
    "print(\"Loading Embedding Model (untuk metrik Ragas)...\")\n",
    "\n",
    "evaluator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',\n",
    "\n",
    "    },\n",
    "    encode_kwargs={\n",
    "        'normalize_embeddings': True,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    multi_process=False \n",
    ")\n",
    "\n",
    "# STEP 2: LOAD DATASET DARI EXCEL (LANGSUNG EVALUASI)\n",
    "file_path = input_dir \n",
    "print(f\"Membaca file dataset: {file_path}\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "def parse_contexts(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    try:\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "print(\"Melakukan konversi format data (String -> List)...\")\n",
    "if 'contexts' in df.columns:\n",
    "    df['contexts'] = df['contexts'].apply(parse_contexts)\n",
    "else:\n",
    "    raise ValueError(\"Kolom 'contexts' tidak ditemukan di Excel!\")\n",
    "if 'ground_truth' in df.columns:\n",
    "    df['ground_truth'] = df['ground_truth'].astype(str)\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "print(\"Data berhasil dimuat dan diproses.\")\n",
    "\n",
    "\n",
    "# STEP 3: JALANKAN EVALUASI RAGAS\n",
    "rag_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "metrics = [context_precision, faithfulness, answer_relevancy, context_recall]\n",
    "\n",
    "print(\"\\nMemulai Evaluasi Ragas...\")\n",
    "# Jalankan Evaluasi\n",
    "results = evaluate(\n",
    "    dataset=rag_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"HASIL AKHIR SKOR RAGAS\")\n",
    "print(\"=\"*30)\n",
    "print(results)\n",
    "print(\"=\"*30)\n",
    "\n",
    "\n",
    "# STEP 4: SAVE HASIL KE EXCEL BARU\n",
    "metrics_df = results.to_pandas()\n",
    "\n",
    "df_reset = df.reset_index(drop=True)\n",
    "metrics_reset = metrics_df.reset_index(drop=True)\n",
    "final_df = pd.concat([df_reset, metrics_reset], axis=1)\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "cols_target = ['question', 'answer', 'contexts', 'ground_truth', \n",
    "               'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "final_cols = [c for c in cols_target if c in final_df.columns]\n",
    "final_df = final_df[final_cols]\n",
    "output_filename = output_dir\n",
    "final_df.to_excel(output_filename, index=False)\n",
    "print(f\"\\nFile hasil evaluasi disimpan: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27886144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
